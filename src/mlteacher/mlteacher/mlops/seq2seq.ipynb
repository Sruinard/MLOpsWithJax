{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "jaxlib version 0.3.20 is newer than and incompatible with jax version 0.3.15. Please update your jax and/or jaxlib packages.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_ext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransform\u001b[39;00m\n\u001b[1;32m      5\u001b[0m vocab \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0123456789+=\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m char_lookup_table \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mCharacterTable(vocab)\n",
      "File \u001b[0;32m/workspaces/MLOpsWithJax/src/mlteacher/mlteacher/mlops/transform.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, Dict\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjax\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mjnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjax\u001b[39;00m \u001b[39mimport\u001b[39;00m random\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/jax/__init__.py:35\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdel\u001b[39;00m _cloud_tpu_init\n\u001b[1;32m     32\u001b[0m \u001b[39m# Confusingly there are two things named \"config\": the module and the class.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39m# We want the exported object to be the class, so we first import the module\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39m# to make sure a later import doesn't overwrite the class.\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjax\u001b[39;00m \u001b[39mimport\u001b[39;00m config \u001b[39mas\u001b[39;00m _config_module\n\u001b[1;32m     36\u001b[0m \u001b[39mdel\u001b[39;00m _config_module\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_src\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     39\u001b[0m   config \u001b[39mas\u001b[39;00m config,\n\u001b[1;32m     40\u001b[0m   enable_checks \u001b[39mas\u001b[39;00m enable_checks,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m   transfer_guard_device_to_host \u001b[39mas\u001b[39;00m transfer_guard_device_to_host,\n\u001b[1;32m     58\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/jax/config.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2018 Google LLC\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[39m# TODO(phawkins): fix users of this alias and delete this file.\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_src\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m config\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/jax/_src/config.py:29\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mabsl\u001b[39;00m \u001b[39mimport\u001b[39;00m logging\n\u001b[0;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_src\u001b[39;00m \u001b[39mimport\u001b[39;00m lib\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_src\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlib\u001b[39;00m \u001b[39mimport\u001b[39;00m jax_jit\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_src\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlib\u001b[39;00m \u001b[39mimport\u001b[39;00m transfer_guard_lib\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/jax/_src/lib/__init__.py:87\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[39mreturn\u001b[39;00m _jaxlib_version\n\u001b[1;32m     86\u001b[0m version_str \u001b[39m=\u001b[39m jaxlib\u001b[39m.\u001b[39mversion\u001b[39m.\u001b[39m__version__\n\u001b[0;32m---> 87\u001b[0m version \u001b[39m=\u001b[39m check_jaxlib_version(\n\u001b[1;32m     88\u001b[0m   jax_version\u001b[39m=\u001b[39;49mjax\u001b[39m.\u001b[39;49mversion\u001b[39m.\u001b[39;49m__version__,\n\u001b[1;32m     89\u001b[0m   jaxlib_version\u001b[39m=\u001b[39;49mjaxlib\u001b[39m.\u001b[39;49mversion\u001b[39m.\u001b[39;49m__version__,\n\u001b[1;32m     90\u001b[0m   minimum_jaxlib_version\u001b[39m=\u001b[39;49mjax\u001b[39m.\u001b[39;49mversion\u001b[39m.\u001b[39;49m_minimum_jaxlib_version)\n\u001b[1;32m     94\u001b[0m \u001b[39m# Before importing any C compiled modules from jaxlib, first import the CPU\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39m# feature guard module to verify that jaxlib was compiled in a way that only\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39m# uses instructions that are present on this machine.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjaxlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcpu_feature_guard\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mcpu_feature_guard\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/jax/_src/lib/__init__.py:82\u001b[0m, in \u001b[0;36mcheck_jaxlib_version\u001b[0;34m(jax_version, jaxlib_version, minimum_jaxlib_version)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mif\u001b[39;00m _jaxlib_version \u001b[39m>\u001b[39m _jax_version:\n\u001b[1;32m     79\u001b[0m   msg \u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mjaxlib version \u001b[39m\u001b[39m{\u001b[39;00mjaxlib_version\u001b[39m}\u001b[39;00m\u001b[39m is newer than and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     80\u001b[0m          \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mincompatible with jax version \u001b[39m\u001b[39m{\u001b[39;00mjax_version\u001b[39m}\u001b[39;00m\u001b[39m. Please \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     81\u001b[0m          \u001b[39m'\u001b[39m\u001b[39mupdate your jax and/or jaxlib packages.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 82\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m     84\u001b[0m \u001b[39mreturn\u001b[39;00m _jaxlib_version\n",
      "\u001b[0;31mRuntimeError\u001b[0m: jaxlib version 0.3.20 is newer than and incompatible with jax version 0.3.15. Please update your jax and/or jaxlib packages."
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import transform\n",
    "\n",
    "vocab = \"0123456789+=\"\n",
    "char_lookup_table = transform.CharacterTable(vocab)\n",
    "list(char_lookup_table.generate_samples(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs shape: (12, 8, 14)\n",
      "targets shape: (12, 8, 14)\n",
      "shape: batch_size, sequence_length, vocab_size\n"
     ]
    }
   ],
   "source": [
    "batch = char_lookup_table.get_batch(12)\n",
    "print(f\"inputs shape: {batch['query'].shape}\")\n",
    "print(f\"targets shape: {batch['answer'].shape}\")\n",
    "print(f\"shape: batch_size, sequence_length, vocab_size\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "labels = batch['answer']\n",
    "eos_row = labels[:, :, char_lookup_table.eos_id] # as we are dealing with a one hot encoded variable and we now the eos_id, we can select the column\n",
    "# representing the eos_id and find it's argmax. Because if we find it's argmax, we know everything after that index will be padded.\n",
    "\n",
    "print(labels[0, :]) # looking at a single sample it becomes more obvious. The eos_id = 1, in addition, the pad token is 0. \n",
    "# so if you look down the first column until you see the first 1 (i.e. the row containing the eos token), than we know that everything after \n",
    "# that row AND in the pad token column (i.e. column 0) should be equal to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_idx = jnp.argmax(eos_row, axis=-1) # get the first occurence when we get the end of sentence id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eos_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "jnp.where(\n",
    "    eos_row[jnp.arange(eos_row.shape[0]), eos_idx],\n",
    "    eos_idx + 1, # the +1 makes sure we include the eos token, which will also be needed during inference to know when to stop\n",
    "    labels.shape[1] # if no eos id is present, use the entire sequence as target\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets take an example. If the inputs = `120+123` than the target = `=243`\n",
    "in addition, lets say we have the following char_to_idx mapping: \n",
    "```\n",
    "{\n",
    "    0: '_',\n",
    "    1: '|',\n",
    "    2: '+',\n",
    "    3: '0',\n",
    "    4: '1',\n",
    "    5: '2',\n",
    "    6: '3',\n",
    "    7: '4',\n",
    "    8: '5',\n",
    "    9: '6',\n",
    "    10: '7',\n",
    "    11: '8',\n",
    "    12: '9',\n",
    "    13: '='\n",
    " }\n",
    "```\n",
    "the target becomes \n",
    "```\n",
    "[\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], <-- =\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], <-- 2\n",
    "    [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], <-- 4\n",
    "    [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], <-- 3\n",
    "    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], <-- |\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], <-- _\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], <-- _\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], <-- _\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], <-- _\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], <-- _\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], <-- _\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], <-- _\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "              [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "              [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],            dtype=float32),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "from transform import get_sequence_lengths\n",
    "\n",
    "def mask_sequences(sequence_batch: jnp.ndarray, lengths: jnp.ndarray) -> jnp.ndarray:\n",
    "  \"\"\"Sets positions beyond the length of each sequence to 0.\"\"\"\n",
    "  return sequence_batch * (\n",
    "      lengths[:, jnp.newaxis] > jnp.arange(sequence_batch.shape[1])[jnp.newaxis])[..., jnp.newaxis]\n",
    "\n",
    "lengths = get_sequence_lengths(labels, char_lookup_table.eos_id)\n",
    "masked_labels = mask_sequences(labels, lengths)\n",
    "\n",
    "\n",
    "# note that in the masked_labels, all padded rows are set to 0\n",
    "# whereas the labels still contain the padded one_hot encoded elements\n",
    "masked_labels[0], labels[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 1) (1, 8)\n",
      "[[5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]]\n",
      "[[0 1 2 3 4 5 6 7]]\n",
      "[[1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "labels.shape\n",
    "lengths = get_sequence_lengths(labels, char_lookup_table.eos_id)\n",
    "lengths_expanded = lengths[:, jnp.newaxis] # from shape (batch_size,) to (batch_size, 1)\n",
    "jnp.arange(labels.shape[1]) # array for each element in the sequence. shape = (sequence_length,)\n",
    "sequence_expanded = jnp.arange(labels.shape[1])[jnp.newaxis] # array for each element in the sequence. shape = (1, sequence_length)\n",
    "\n",
    "# shapes are (batch_size, 1), (1, sequence_length)\n",
    "print(lengths_expanded.shape, sequence_expanded.shape)\n",
    "\n",
    "# if we compare them using the > operation, we are creating a boolean matrix\n",
    "# which returns true for each element where the sequence length > labels index\n",
    "print(lengths_expanded)\n",
    "print(sequence_expanded)\n",
    "print(1.0 * (lengths_expanded > sequence_expanded)) # multiply by 1.0 to turn boolean into float\n",
    "masks = 1.0 * (lengths_expanded > sequence_expanded)\n",
    "# masks.shape = (batch_size, sequence_size)\n",
    "masks.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inputs --> encoder --> embedding_representation_input_domain --> decoder --> embedding_representation_target_domain --> dense --> predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax.linen as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my interpretation of the nn.scan functionality is as follows\n",
    "- nn.scan can be seen as a for loop with state carried over at each step\n",
    "- the first argument is the operation that we want to apply (in our case, we want to feed each step through the lstmcell, so the operation is the nn.LSTMCell).\n",
    "- We specify the variable_broadcast. This value is shared across each step and has no dependencies. Recall that the weights of an LSTMCell are shared. As such, we can provide these weights at each time step. Stated differently, we are broadcasting them at each time step\n",
    "- we set split_rngs for the params to false. We don't want to create random parameters at each time step\n",
    "- now lets move over to the axes. In the aforementioned documentation, I'm constantly talking about timesteps. The axes is what allows me to talk about it in this way. Remember, the inputs are of shape (batch_size, timesteps, n_features). by specifying in_axis=1, we are saying, apply this function over the first dimension (i.e. the timesteps/sequence axis).\n",
    "- out_axis specifies the axis where the result will be added to (i.e. the dimension to place the results). As such, the output will have an extra dimension/axis at the position indicated by the `out_axis` (e.g. in the case of one sample with 10 output features, the shape would be (1, 10). with out_axis=1 the result would become (1, 1, 10))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/linen/transforms.py:138: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  new_args, new_kwargs = jax.tree_map(get_arg_scope, (args, kwargs))\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/linen/transforms.py:157: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  jax.tree_map(get_scopes_inner, attrs)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/lift.py:112: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  scopes, treedef = jax.tree_flatten(scope_tree)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/scope.py:322: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  group[col] = jax.tree_map(lambda x: x, xs[col])\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/lift.py:723: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  lengths = jax.tree_map(find_length, in_axes, args)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/lift.py:718: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  leaves = jax.tree_leaves(x)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/lift.py:724: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  lengths = set(jax.tree_leaves(lengths))\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/axes_scan.py:105: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  xs = jax.tree_map(transpose_to_front, in_axes, args)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/axes_scan.py:87: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  return jax.tree_map(trans, xs)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/axes_scan.py:123: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  carry_avals = jax.tree_map(\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/axes_scan.py:126: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  scan_avals = jax.tree_map(\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/axes_scan.py:131: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  in_avals, in_tree = jax.tree_flatten(input_avals)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/axes_scan.py:109: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  xs = jax.tree_map(lambda ax, arg, x: (arg if ax is broadcast else x),\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/lift.py:172: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  variables = jax.tree_map(lambda x: x, variables)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/linen/transforms.py:210: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  new_args, new_kwargs = jax.tree_map(\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/linen/transforms.py:235: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  new_attrs = jax.tree_map(set_scopes_inner, attrs)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/linen/transforms.py:247: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  jax.tree_leaves(tree)))\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/axes_scan.py:114: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  ys = jax.tree_map(lambda ax, y: (y if ax is broadcast else ()),\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/axes_scan.py:143: FutureWarning: jax.tree_unflatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_unflatten instead.\n",
      "  broadcast_in, constants_out = jax.tree_unflatten(out_tree(), out_flat)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/scope.py:740: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  abs_value_flat = jax.tree_leaves(abs_value)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/scope.py:741: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  value_flat = jax.tree_leaves(value)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/axes_scan.py:118: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  ys = jax.tree_map(lambda ax, y: (() if ax is broadcast else y),\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/axes_scan.py:146: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  ys = jax.tree_map(transpose_from_front, out_axes, ys)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/axes_scan.py:102: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  return jax.tree_map(trans, xs)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/axes_scan.py:147: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  ys = jax.tree_map(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16, 20, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example taken from flax documentation\n",
    "# --> https://flax.readthedocs.io/en/latest/api_reference/_autosummary/flax.linen.scan.html?highlight=flax%20scan\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "from jax import random\n",
    "\n",
    "class SimpleScan(nn.Module):\n",
    "  @nn.compact\n",
    "  def __call__(self, c, xs):\n",
    "    LSTM = nn.scan(nn.LSTMCell,\n",
    "                   variable_broadcast=\"params\",\n",
    "                   split_rngs={\"params\": False},\n",
    "                   in_axes=1,\n",
    "                   out_axes=1)\n",
    "    return LSTM()(c, xs)\n",
    "\n",
    "batch_size, seq_len, in_feat, out_feat = 16, 20, 3, 5\n",
    "key_1, key_2, key_3 = random.split(random.PRNGKey(0), 3)\n",
    "\n",
    "xs = random.uniform(key_1, (batch_size, seq_len, in_feat))\n",
    "init_carry = nn.LSTMCell.initialize_carry(key_2, (batch_size,), out_feat)\n",
    "\n",
    "model = SimpleScan()\n",
    "variables = model.init(key_3, init_carry, xs)\n",
    "out_carry, out_val = model.apply(variables, init_carry, xs)\n",
    "\n",
    "assert out_val.shape == (batch_size, seq_len, out_feat)\n",
    "out_val.shape \n",
    "# for each sample in the the batch (16 in total), at each time step (20 in total)\n",
    "# we have the knowledge 'encoded' in a 5 dimensional vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_carry[0].shape\n",
    "out_carry[1].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the encoder part of the model\n",
    "\n",
    "def select_carried_state(new_state, old_state):\n",
    "    return jnp.where(is_eos[:, np.newaxis], old_state, new_state)\n",
    "\n",
    "\n",
    "\n",
    "initial_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from typing import Any, Tuple\n",
    "\n",
    "from flax import linen as nn\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "Array = Any\n",
    "PRNGKey = Any\n",
    "\n",
    "class EncoderLSTM(nn.Module):\n",
    "  \"\"\"EncoderLSTM Module wrapped in a lifted scan transform.\"\"\"\n",
    "  eos_id: int\n",
    "\n",
    "  @functools.partial(\n",
    "      nn.scan,\n",
    "      variable_broadcast='params',\n",
    "      in_axes=1,\n",
    "      out_axes=1,\n",
    "      split_rngs={'params': False})\n",
    "  @nn.compact\n",
    "  def __call__(self, carry: Tuple[Array, Array],\n",
    "               x: Array) -> Tuple[Tuple[Array, Array], Array]:\n",
    "    \"\"\"Applies the module.\"\"\"\n",
    "    lstm_state, is_eos = carry\n",
    "    new_lstm_state, y = nn.LSTMCell()(lstm_state, x)\n",
    "    # Pass forward the previous state if EOS has already been reached.\n",
    "    def select_carried_state(new_state, old_state):\n",
    "      return jnp.where(is_eos[:, np.newaxis], old_state, new_state)\n",
    "    # LSTM state is a tuple (cell_state, hidden_state).\n",
    "    # we need to select what state to carry for both \n",
    "    # the cell_state as the hidden_state\n",
    "    carried_lstm_state = tuple(\n",
    "        select_carried_state(*s) for s in zip(new_lstm_state, lstm_state))\n",
    "    # Update `is_eos`.\n",
    "    is_eos = jnp.logical_or(is_eos, x[:, self.eos_id])\n",
    "    return (carried_lstm_state, is_eos), y\n",
    "\n",
    "  @staticmethod\n",
    "  def initialize_carry(batch_size: int, hidden_size: int) -> Tuple[Array, Array]:\n",
    "    # Use a dummy key since the default state init fn is just zeros.\n",
    "    return nn.LSTMCell.initialize_carry(\n",
    "        jax.random.PRNGKey(0), (batch_size,), hidden_size)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  \"\"\"LSTM encoder, returning state after finding the EOS token in the input.\"\"\"\n",
    "  hidden_size: int\n",
    "  eos_id: int\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, inputs: Array):\n",
    "    # inputs.shape = (batch_size, seq_length, vocab_size).\n",
    "    batch_size = inputs.shape[0]\n",
    "    lstm = EncoderLSTM(name='encoder_lstm', eos_id=self.eos_id)\n",
    "    init_lstm_state = lstm.initialize_carry(batch_size, self.hidden_size)\n",
    "    # We use the `is_eos` array to determine whether the encoder should carry\n",
    "    # over the last lstm state, or apply the LSTM cell on the previous state.\n",
    "    init_is_eos = jnp.zeros(batch_size, dtype=bool)\n",
    "    init_carry = (init_lstm_state, init_is_eos)\n",
    "    (final_state, _), _ = lstm(init_carry, inputs)\n",
    "    return final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],            dtype=float32),\n",
       " DeviceArray([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],            dtype=float32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.LSTMCell().initialize_carry(jax.random.PRNGKey(0), (16, ), 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 12, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:, eos_idx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'answer'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 8, 14)\n",
      "(16, 12, 14)\n",
      "['49+688']\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'+': 2,\n",
       " '0': 3,\n",
       " '1': 4,\n",
       " '2': 5,\n",
       " '3': 6,\n",
       " '4': 7,\n",
       " '5': 8,\n",
       " '6': 9,\n",
       " '7': 10,\n",
       " '8': 11,\n",
       " '9': 12,\n",
       " '=': 13}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = char_lookup_table.get_batch(16) \n",
    "print(batch['query'].shape)\n",
    "print(batch['query'][:, eos_idx].shape)\n",
    "print(char_lookup_table.decode_onehot(batch['query'][:1]))\n",
    "print(batch['query'][0][:,eos_idx])\n",
    "char_lookup_table._char_indices\n",
    "\n",
    "# char_lookup_table.decode(batch['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([ True,  True,  True, False], dtype=bool)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in the network we initialize the is_eos with all zeros\n",
    "# then we compute the logical_or based on the input sequence where the id == eos_id\n",
    "# Finally, we take the xor, updating the is_eos matrix to contain ones, where the \n",
    "# is_eos matrix is one or the input_matrix is one \n",
    "jnp.logical_or(jnp.array([1,0,1,0]), jnp.array([1,1,0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "hidden_size = 512\n",
    "batch = char_lookup_table.get_batch(batch_size)\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "\n",
    "encoder_model = Encoder(hidden_size, char_lookup_table.eos_id)\n",
    "example = jnp.ones((1, char_lookup_table.max_input_len, char_lookup_table.vocab_size), jnp.float32)\n",
    "variables = encoder_model.init(rng, example)\n",
    "model_params = variables['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 8, 14)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['query'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoding = encoder_model.apply({\n",
    "    \"params\": model_params\n",
    "}, batch['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 512), (32, 512))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding[0].shape, encoding[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'answer'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DecoderLSTM(nn.Module):\n",
    "  \"\"\"DecoderLSTM Module wrapped in a lifted scan transform.\n",
    "  Attributes:\n",
    "    teacher_force: See docstring on Seq2seq module.\n",
    "    vocab_size: Size of the vocabulary.\n",
    "  \"\"\"\n",
    "  teacher_force: bool\n",
    "  vocab_size: int\n",
    "\n",
    "  @functools.partial(\n",
    "      nn.scan,\n",
    "      variable_broadcast='params',\n",
    "      in_axes=1,\n",
    "      out_axes=1,\n",
    "      split_rngs={'params': False, 'lstm': True})\n",
    "  @nn.compact\n",
    "  def __call__(self, carry: Tuple[Array, Array], x: Array) -> Array:\n",
    "    \"\"\"Applies the DecoderLSTM model.\"\"\"\n",
    "    lstm_state, last_prediction = carry\n",
    "    if not self.teacher_force:\n",
    "      x = last_prediction\n",
    "    lstm_state, y = nn.LSTMCell()(lstm_state, x)\n",
    "    logits = nn.Dense(features=self.vocab_size)(y)\n",
    "    # Sample the predicted token using a categorical distribution over the\n",
    "    # logits.\n",
    "    categorical_rng = self.make_rng('lstm')\n",
    "    predicted_token = jax.random.categorical(categorical_rng, logits)\n",
    "    # Convert to one-hot encoding.\n",
    "    prediction = jax.nn.one_hot(\n",
    "        predicted_token, self.vocab_size, dtype=jnp.float32)\n",
    "\n",
    "    return (lstm_state, prediction), (logits, prediction)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "  \"\"\"LSTM decoder.\n",
    "  Attributes:\n",
    "    init_state: [batch_size, hidden_size]\n",
    "      Initial state of the decoder (i.e., the final state of the encoder).\n",
    "    teacher_force: See docstring on Seq2seq module.\n",
    "    vocab_size: Size of the vocabulary.\n",
    "  \"\"\"\n",
    "  init_state: Tuple[Any]\n",
    "  teacher_force: bool\n",
    "  vocab_size: int\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, inputs: Array) -> Tuple[Array, Array]:\n",
    "    \"\"\"Applies the decoder model.\n",
    "    Args:\n",
    "      inputs: [batch_size, max_output_len-1, vocab_size]\n",
    "        Contains the inputs to the decoder at each time step (only used when not\n",
    "        using teacher forcing). Since each token at position i is fed as input\n",
    "        to the decoder at position i+1, the last token is not provided.\n",
    "    Returns:\n",
    "      Pair (logits, predictions), which are two arrays of respectively decoded\n",
    "      logits and predictions (in one hot-encoding format).\n",
    "    \"\"\"\n",
    "    lstm = DecoderLSTM(teacher_force=self.teacher_force,\n",
    "                       vocab_size=self.vocab_size)\n",
    "    init_carry = (self.init_state, inputs[:, 0])\n",
    "    _, (logits, predictions) = lstm(init_carry, inputs)\n",
    "    return logits, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = Decoder(init_state=encoding, teacher_force=False, vocab_size=char_lookup_table.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_decoder_input = char_lookup_table.one_hot(char_lookup_table.encode('=')[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "init_decoder_inputs = jnp.tile(init_decoder_input,\n",
    "                                (batch['query'].shape[0], char_lookup_table.max_output_len, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 14), (32, 6, 14))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_decoder_input.shape, init_decoder_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/lift.py:42: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  return jax.tree_map(\n"
     ]
    }
   ],
   "source": [
    "key_1, key_2 = jax.random.split(jax.random.PRNGKey(0))\n",
    "decoder_params = d.init({\"params\":key_1, \"lstm\": key_2}, init_decoder_inputs)\n",
    "# d.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_rng = jax.random.PRNGKey(0)\n",
    "step = 200\n",
    "# we need a random key as our decoder samples \n",
    "# using a categorical distibution based on the logits\n",
    "lstm_key = jax.random.fold_in(lstm_rng, step) \n",
    "\n",
    "logits, predictions = d.apply(decoder_params, init_decoder_inputs, rngs={'lstm': lstm_key})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 6, 14), (32, 6, 14))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['98+971' '29+164' '52+142' '30+777' '94+319' '39+66' '19+235' '65+605'\n",
      " '45+234' '97+187' '58+886' '65+668' '65+848' '71+809' '24+852' '33+969'\n",
      " '41+536' '68+644' '87+204' '74+668' '34+367' '26+629' '81+135' '88+7'\n",
      " '92+227' '27+432' '86+383' '38+416' '63+351' '62+980' '95+734' '3+282']\n",
      "['=1069' '=193' '=194' '=807' '=413' '=105' '=254' '=670' '=279' '=284'\n",
      " '=944' '=733' '=913' '=880' '=876' '=1002' '=577' '=712' '=291' '=742'\n",
      " '=401' '=655' '=216' '=95' '=319' '=459' '=469' '=454' '=414' '=1042'\n",
      " '=829' '=285']\n",
      "['63' '0' '300=0=' '98' '10+316' '1734=4' '' '0' '=0_=+1' '620533'\n",
      " '435923' '7_94+' '30=4' '70=1+5' '6+9262' '583' '082297' '+30825'\n",
      " '_96=95' '2=6711' '408' '3+3' '25' '2_506+' '=56+31' '5_7510' '_31=83'\n",
      " '453736' '95+547' '5=_' '02' '_575=5']\n"
     ]
    }
   ],
   "source": [
    "# model isn't trained, but here are the results (query, target, prediction)\n",
    "print(char_lookup_table.decode_onehot(batch['query']))\n",
    "print(char_lookup_table.decode_onehot(batch['answer']))\n",
    "print(char_lookup_table.decode_onehot(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(nn.Module):\n",
    "\n",
    "    teacher_force: bool\n",
    "    hidden_size: int\n",
    "    vocab_size: int\n",
    "    eos_id: int = 1\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, encoder_inputs, decoder_inputs):\n",
    "        initial_decoder_state = Encoder(\n",
    "            hidden_size=self.hidden_size,\n",
    "            eos_id=self.eos_id\n",
    "        )(encoder_inputs)\n",
    "\n",
    "        logits, predictions = Decoder(\n",
    "            init_state=initial_decoder_state,\n",
    "            teacher_force=self.teacher_force,\n",
    "            vocab_size=self.vocab_size\n",
    "        )(decoder_inputs[:, :-1])\n",
    "        return logits, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_force = False\n",
    "hidden_size = 512\n",
    "eos_id = char_lookup_table.eos_id\n",
    "vocab_size = char_lookup_table.vocab_size\n",
    "model = Seq2seq(\n",
    "    teacher_force=teacher_force,\n",
    "    hidden_size=hidden_size,\n",
    "    vocab_size=vocab_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "params_key, lstm_key = jax.random.split(rng)\n",
    "max_input_sequence_len = char_lookup_table.max_input_len\n",
    "max_output_sequence_len = char_lookup_table.max_output_len\n",
    "variables = model.init(\n",
    "    {\n",
    "        \"params\": params_key,\n",
    "        \"lstm\": lstm_key\n",
    "    },\n",
    "    jnp.ones((batch_size, max_input_sequence_len, vocab_size), dtype=jnp.float32),\n",
    "    jnp.ones((batch_size, max_output_sequence_len, vocab_size), dtype=jnp.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozen_dict_keys(['params'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([[[ 0.08307394, -0.06417654,  0.11232382, ...,  0.04796918,\n",
       "                 0.08337983, -0.04808454],\n",
       "               [-0.04887169,  0.02889351,  0.08376509, ..., -0.0573354 ,\n",
       "                 0.02569693, -0.01780605],\n",
       "               [ 0.07617846, -0.06507105,  0.15715244, ...,  0.07221642,\n",
       "                 0.12518902, -0.0459436 ],\n",
       "               ...,\n",
       "               [ 0.08691359, -0.09904549,  0.05844625, ...,  0.03085802,\n",
       "                -0.13066357, -0.01850299],\n",
       "               [ 0.17952195,  0.04801203,  0.10827539, ..., -0.02468754,\n",
       "                 0.0370799 , -0.06572822],\n",
       "               [ 0.03389015,  0.00849534,  0.0068223 , ...,  0.00689863,\n",
       "                 0.0393358 , -0.11326101]],\n",
       " \n",
       "              [[ 0.09038381, -0.08036304,  0.10141592, ...,  0.02821084,\n",
       "                 0.10218308, -0.02035185],\n",
       "               [ 0.13380422,  0.05083488,  0.04915942, ..., -0.10524669,\n",
       "                 0.10610627,  0.05437368],\n",
       "               [ 0.1284994 ,  0.04025817,  0.10398245, ...,  0.0349204 ,\n",
       "                 0.05961333,  0.07432193],\n",
       "               ...,\n",
       "               [ 0.09459567,  0.04841722,  0.01790352, ...,  0.04476517,\n",
       "                 0.10109463, -0.04270589],\n",
       "               [ 0.00675489,  0.00334709, -0.00370746, ...,  0.04632333,\n",
       "                 0.06944169, -0.02370582],\n",
       "               [-0.09398853,  0.09772126,  0.07149192, ...,  0.00074859,\n",
       "                 0.0656438 ,  0.06745849]],\n",
       " \n",
       "              [[ 0.07680565, -0.09538081,  0.09987976, ...,  0.04093312,\n",
       "                 0.1050894 , -0.04485584],\n",
       "               [ 0.13545579,  0.03345525,  0.07192907, ..., -0.10171738,\n",
       "                 0.10734063,  0.05127335],\n",
       "               [ 0.16030747,  0.06720173,  0.04631138, ..., -0.03007051,\n",
       "                 0.11283469, -0.01511302],\n",
       "               ...,\n",
       "               [ 0.02307737,  0.02021651,  0.00511848, ...,  0.01125195,\n",
       "                 0.08222268,  0.09970434],\n",
       "               [ 0.11171512, -0.06451995,  0.05473147, ...,  0.06351745,\n",
       "                -0.03447008,  0.1520299 ],\n",
       "               [ 0.1278329 ,  0.01526029, -0.00529008, ...,  0.03921251,\n",
       "                 0.08008413,  0.02792082]],\n",
       " \n",
       "              ...,\n",
       " \n",
       "              [[ 0.08257927, -0.10460095,  0.12600534, ...,  0.00957109,\n",
       "                 0.07924028, -0.05781667],\n",
       "               [ 0.18267936,  0.06472795,  0.14642555, ..., -0.01868905,\n",
       "                 0.11242551, -0.10092239],\n",
       "               [ 0.1701081 ,  0.07056701,  0.1303871 , ...,  0.08835557,\n",
       "                 0.04416277, -0.01921787],\n",
       "               ...,\n",
       "               [ 0.05628004, -0.03972441, -0.02750922, ...,  0.07301001,\n",
       "                 0.05038077,  0.0243116 ],\n",
       "               [ 0.04917509, -0.06423827, -0.0043033 , ...,  0.08566882,\n",
       "                -0.03706946, -0.05800579],\n",
       "               [ 0.12986106, -0.09331776, -0.10167679, ...,  0.13042092,\n",
       "                -0.12303941,  0.01904944]],\n",
       " \n",
       "              [[ 0.12249661, -0.10386096,  0.14680502, ...,  0.03140073,\n",
       "                 0.1209379 , -0.02279596],\n",
       "               [ 0.15850413, -0.09523652,  0.03450573, ...,  0.08974424,\n",
       "                 0.06074852, -0.11927556],\n",
       "               [ 0.02610465, -0.03669495, -0.02579285, ...,  0.05154156,\n",
       "                 0.04512806, -0.10227554],\n",
       "               ...,\n",
       "               [-0.09281497, -0.03002914, -0.06460758, ...,  0.0139387 ,\n",
       "                 0.02901088, -0.01999728],\n",
       "               [-0.15697698,  0.07957149,  0.02117227, ..., -0.02148688,\n",
       "                 0.05300506,  0.04192068],\n",
       "               [-0.05830166, -0.0179526 ,  0.04880999, ...,  0.09537116,\n",
       "                -0.0014839 ,  0.09850807]],\n",
       " \n",
       "              [[ 0.04347707, -0.11192491,  0.11110252, ...,  0.05734334,\n",
       "                 0.10103773, -0.08062863],\n",
       "               [ 0.16898783,  0.03910859,  0.15406752, ..., -0.0004376 ,\n",
       "                 0.12748009, -0.09469486],\n",
       "               [ 0.18890624,  0.00332251,  0.03636713, ...,  0.08977721,\n",
       "                 0.06128837, -0.1817157 ],\n",
       "               ...,\n",
       "               [-0.01285942,  0.06446112,  0.02878608, ..., -0.06165402,\n",
       "                 0.02645415, -0.04286392],\n",
       "               [ 0.18508667,  0.1365033 ,  0.10097197, ..., -0.040463  ,\n",
       "                 0.13365299, -0.06287558],\n",
       "               [ 0.16189827, -0.010416  ,  0.13511407, ...,  0.09229138,\n",
       "                 0.15598388, -0.09069349]]], dtype=float32),\n",
       " DeviceArray([[[0., 1., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 1.],\n",
       "               [1., 0., 0., ..., 0., 0., 0.],\n",
       "               ...,\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 1., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "              [[0., 0., 0., ..., 1., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 1., ..., 0., 0., 0.],\n",
       "               ...,\n",
       "               [0., 0., 1., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 1., ..., 0., 0., 0.]],\n",
       " \n",
       "              [[0., 0., 0., ..., 1., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               ...,\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "              ...,\n",
       " \n",
       "              [[0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               ...,\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "              [[0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 1., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 1., 0.],\n",
       "               ...,\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "              [[0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               ...,\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 1.],\n",
       "               [0., 0., 0., ..., 1., 0., 0.]]], dtype=float32))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(variables, batch['query'], batch['answer'], rngs={\n",
    "    \"lstm\": lstm_key\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 8, 14)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# model.apply(variables, batch['query'], batch['answer'], rngs={\n",
    "#     \"lstm\": lstm_key\n",
    "# })\n",
    "# during inference you provide the start_of_sentence token\n",
    "# which in our case is the '=' character \n",
    "batch['answer'].shape # <-- input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 6, 14)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_decoder_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],            dtype=float32),\n",
       " {'+': 2,\n",
       "  '0': 3,\n",
       "  '1': 4,\n",
       "  '2': 5,\n",
       "  '3': 6,\n",
       "  '4': 7,\n",
       "  '5': 8,\n",
       "  '6': 9,\n",
       "  '7': 10,\n",
       "  '8': 11,\n",
       "  '9': 12,\n",
       "  '=': 13})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_decoder_inputs[0], char_lookup_table._char_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Seq2seq\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import functools\n",
    "from typing import Callable, Dict, List\n",
    "\n",
    "import absl\n",
    "\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "from flax.metrics import tensorboard\n",
    "import flax.optim\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from jax.experimental import jax2tf\n",
    "from mlteacher.mlops.transform import CharacterTable\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# The transformed feature names\n",
    "\n",
    "# Type abbreviations: (B is the batch size)\n",
    "_Array = np.ndarray\n",
    "_InputBatch = Dict[str,\n",
    "                   _Array]  # keys are _FEATURE_KEYS_XF and values f32[B, 1]\n",
    "_LogitBatch = _Array  # of shape f32[B, 3]\n",
    "_LabelBatch = _Array  # of shape int64[B, 1]\n",
    "_Params = Dict[str, _Array]\n",
    "\n",
    "\n",
    "class _SavedModelWrapper(tf.train.Checkpoint):\n",
    "  \"\"\"Wraps a function and its parameters for saving to a SavedModel.\n",
    "  Implements the interface described at\n",
    "  https://www.tensorflow.org/hub/reusable_saved_models.\n",
    "  This class contains all the code needed to convert a Flax model to a\n",
    "  TensorFlow saved model.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               tf_graph: Callable[[_InputBatch], _Array],\n",
    "               param_vars: Dict[str, tf.Variable]):\n",
    "    \"\"\"Builds the tf.Module.\n",
    "    Args:\n",
    "      tf_graph: a tf.function taking one argument (the inputs), which can be be\n",
    "        tuples/lists/dictionaries of np.ndarray or tensors. The function may\n",
    "        have references to the tf.Variables in `param_vars`.\n",
    "      param_vars: the parameters, as tuples/lists/dictionaries of tf.Variable,\n",
    "        to be saved as the variables of the SavedModel.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    # Implement the interface from\n",
    "    # https://www.tensorflow.org/hub/reusable_saved_models\n",
    "    self.variables = tf.nest.flatten(param_vars)\n",
    "    self.trainable_variables = [v for v in self.variables if v.trainable]\n",
    "    self._tf_graph = tf_graph\n",
    "\n",
    "  @tf.function\n",
    "  def __call__(self, inputs):\n",
    "    return self._tf_graph(inputs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from mlteacher.mlops import train, models\n",
    "\n",
    "def save_model():\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    ctable = CharacterTable(\"0123456789=+\")\n",
    "    model = models.Seq2seq(teacher_force=False, hidden_size=512, vocab_size=ctable.vocab_size)\n",
    "    params = train.get_initial_params(model, rng, ctable)\n",
    "\n",
    "    predict_fn = lambda params, input: model.apply({\"params\": params}, *input, rngs={\"lstm\":jax.random.PRNGKey(1)})\n",
    "    tf_fn = jax2tf.convert(predict_fn, with_gradient=False, enable_xla=True)\n",
    "\n",
    "    return tf_fn, params\n",
    "tf_fn, trained_params = save_model()                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'flax.core.frozen_dict.FrozenDict'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_vars = tf.nest.map_structure(\n",
    "    # Due to a bug in SavedModel it is not possible to use tf.GradientTape\n",
    "    # on a function converted with jax2tf and loaded from SavedModel.\n",
    "    # Thus, we mark the variables as non-trainable to ensure that users of\n",
    "    # the SavedModel will not try to fine tune them.\n",
    "    lambda param: tf.Variable(param, trainable=False),\n",
    "    trained_params)\n",
    "tf_graph = tf.function(\n",
    "    lambda inputs, decoder_inputs: tf_fn(param_vars, (inputs, decoder_inputs)),\n",
    "    autograph=False,\n",
    "    experimental_compile=True)\n",
    "\n",
    "signatures = {}\n",
    "# This signature is needed for TensorFlow Serving use.\n",
    "batch_size = 1\n",
    "ctable = CharacterTable(\"0123456789+=\")\n",
    "ctable.get_batch(1, 1)['query'].shape\n",
    "input_signatures = [\n",
    "            tf.TensorSpec((batch_size,) + (ctable.max_input_len, ctable.vocab_size), tf.float32),\n",
    "            tf.TensorSpec((batch_size,) + (ctable.max_output_len, ctable.vocab_size), tf.float32)\n",
    "          ]\n",
    "signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY] = tf_graph.get_concrete_function(input_signatures[0], input_signatures[1])\n",
    "\n",
    "tf_model = _SavedModelWrapper(tf_graph, param_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20221010072911'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, signatures, serving_dir):\n",
    "    latest_model = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    serving_dir = os.path.join(serving_dir, latest_model)\n",
    "    tf.saved_model.save(tf_model, serving_dir, signatures=signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.saved_model.load(\"./models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_default = loaded_model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ctable = CharacterTable(\"0123456789=+\")\n",
    "b = ctable.get_batch(1, 2)\n",
    "q, a = b['query'], b['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_1': <tf.Tensor: shape=(1, 5, 14), dtype=float32, numpy=\n",
       " array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]],\n",
       "       dtype=float32)>,\n",
       " 'output_0': <tf.Tensor: shape=(1, 5, 14), dtype=float32, numpy=\n",
       " array([[[ 0.08430967, -0.08283493,  0.09226608, -0.06462146,\n",
       "           0.0793648 , -0.1541741 , -0.09239573,  0.00601145,\n",
       "          -0.08144277,  0.11923195,  0.03178895,  0.04326432,\n",
       "           0.1258326 , -0.0333593 ],\n",
       "         [ 0.01941263,  0.0411636 ,  0.16464294, -0.03763947,\n",
       "           0.10835177, -0.17228547, -0.13574198, -0.09845351,\n",
       "          -0.01242627,  0.1081738 ,  0.10392632, -0.07437727,\n",
       "           0.04082923, -0.06269556],\n",
       "         [-0.04022854,  0.02152416,  0.06989108,  0.04568947,\n",
       "           0.05994399, -0.20376155, -0.01709659, -0.0048474 ,\n",
       "          -0.0105128 ,  0.06322314,  0.12280601, -0.01808348,\n",
       "           0.0301614 , -0.09793167],\n",
       "         [-0.1249689 ,  0.09185308,  0.10582318, -0.08342357,\n",
       "           0.04525419, -0.07935511,  0.01890675, -0.00223465,\n",
       "          -0.06970923, -0.09640622,  0.05472716, -0.03380135,\n",
       "           0.05015505, -0.01078424],\n",
       "         [-0.0344473 ,  0.09335797,  0.02077004, -0.10002387,\n",
       "          -0.08091511, -0.16607672,  0.08351123,  0.04929334,\n",
       "          -0.07819661, -0.02929778, -0.07825219, -0.00063116,\n",
       "           0.10406539, -0.06673699]]], dtype=float32)>}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_default(inputs=q, decoder_inputs=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.14 ('mlteacher-qwQzX-qT-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08626ac9f967e5febaed3981e0a443fb739b660a4eba71ae8ed7bd4be6194b2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

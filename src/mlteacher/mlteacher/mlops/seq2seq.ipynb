{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('12+84', '=96'),\n",
       " ('19+19', '=38'),\n",
       " ('76+724', '=800'),\n",
       " ('1+955', '=956'),\n",
       " ('79+331', '=410')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import transform\n",
    "\n",
    "vocab = \"0123456789+=\"\n",
    "char_lookup_table = transform.CharacterTable(vocab)\n",
    "list(char_lookup_table.generate_samples(5, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs shape: (12, 8, 14)\n",
      "targets shape: (12, 8, 14)\n",
      "shape: batch_size, sequence_length, vocab_size\n"
     ]
    }
   ],
   "source": [
    "batch = char_lookup_table.get_batch(12)\n",
    "print(f\"inputs shape: {batch['query'].shape}\")\n",
    "print(f\"targets shape: {batch['answer'].shape}\")\n",
    "print(f\"shape: batch_size, sequence_length, vocab_size\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "labels = batch['answer']\n",
    "eos_row = labels[:, :, char_lookup_table.eos_id] # as we are dealing with a one hot encoded variable and we now the eos_id, we can select the column\n",
    "# representing the eos_id and find it's argmax. Because if we find it's argmax, we know everything after that index will be padded.\n",
    "\n",
    "print(labels[0, :]) # looking at a single sample it becomes more obvious. The eos_id = 1, in addition, the pad token is 0. \n",
    "# so if you look down the first column until you see the first 1 (i.e. the row containing the eos token), than we know that everything after \n",
    "# that row AND in the pad token column (i.e. column 0) should be equal to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_idx = jnp.argmax(eos_row, axis=-1) # get the first occurence when we get the end of sentence id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eos_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "jnp.where(\n",
    "    eos_row[jnp.arange(eos_row.shape[0]), eos_idx],\n",
    "    eos_idx + 1, # the +1 makes sure we include the eos token, which will also be needed during inference to know when to stop\n",
    "    labels.shape[1] # if no eos id is present, use the entire sequence as target\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets take an example. If the inputs = `120+123` than the target = `=243`\n",
    "in addition, lets say we have the following char_to_idx mapping: \n",
    "```\n",
    "{\n",
    "    0: '_',\n",
    "    1: '|',\n",
    "    2: '+',\n",
    "    3: '0',\n",
    "    4: '1',\n",
    "    5: '2',\n",
    "    6: '3',\n",
    "    7: '4',\n",
    "    8: '5',\n",
    "    9: '6',\n",
    "    10: '7',\n",
    "    11: '8',\n",
    "    12: '9',\n",
    "    13: '='\n",
    " }\n",
    "```\n",
    "the target becomes \n",
    "```\n",
    "[\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], <-- =\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], <-- 2\n",
    "    [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], <-- 4\n",
    "    [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], <-- 3\n",
    "    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], <-- |\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], <-- _\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], <-- _\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], <-- _\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], <-- _\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], <-- _\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], <-- _\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], <-- _\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "              [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "              [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],            dtype=float32),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "from transform import get_sequence_lengths\n",
    "\n",
    "def mask_sequences(sequence_batch: jnp.ndarray, lengths: jnp.ndarray) -> jnp.ndarray:\n",
    "  \"\"\"Sets positions beyond the length of each sequence to 0.\"\"\"\n",
    "  return sequence_batch * (\n",
    "      lengths[:, jnp.newaxis] > jnp.arange(sequence_batch.shape[1])[jnp.newaxis])[..., jnp.newaxis]\n",
    "\n",
    "lengths = get_sequence_lengths(labels, char_lookup_table.eos_id)\n",
    "masked_labels = mask_sequences(labels, lengths)\n",
    "\n",
    "\n",
    "# note that in the masked_labels, all padded rows are set to 0\n",
    "# whereas the labels still contain the padded one_hot encoded elements\n",
    "masked_labels[0], labels[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 1) (1, 8)\n",
      "[[5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]]\n",
      "[[0 1 2 3 4 5 6 7]]\n",
      "[[1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "labels.shape\n",
    "lengths = get_sequence_lengths(labels, char_lookup_table.eos_id)\n",
    "lengths_expanded = lengths[:, jnp.newaxis] # from shape (batch_size,) to (batch_size, 1)\n",
    "jnp.arange(labels.shape[1]) # array for each element in the sequence. shape = (sequence_length,)\n",
    "sequence_expanded = jnp.arange(labels.shape[1])[jnp.newaxis] # array for each element in the sequence. shape = (1, sequence_length)\n",
    "\n",
    "# shapes are (batch_size, 1), (1, sequence_length)\n",
    "print(lengths_expanded.shape, sequence_expanded.shape)\n",
    "\n",
    "# if we compare them using the > operation, we are creating a boolean matrix\n",
    "# which returns true for each element where the sequence length > labels index\n",
    "print(lengths_expanded)\n",
    "print(sequence_expanded)\n",
    "print(1.0 * (lengths_expanded > sequence_expanded)) # multiply by 1.0 to turn boolean into float\n",
    "masks = 1.0 * (lengths_expanded > sequence_expanded)\n",
    "# masks.shape = (batch_size, sequence_size)\n",
    "masks.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inputs --> encoder --> embedding_representation_input_domain --> decoder --> embedding_representation_target_domain --> dense --> predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax.linen as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my interpretation of the nn.scan functionality is as follows\n",
    "- nn.scan can be seen as a for loop with state carried over at each step\n",
    "- the first argument is the operation that we want to apply (in our case, we want to feed each step through the lstmcell, so the operation is the nn.LSTMCell).\n",
    "- We specify the variable_broadcast. This value is shared across each step and has no dependencies. Recall that the weights of an LSTMCell are shared. As such, we can provide these weights at each time step. Stated differently, we are broadcasting them at each time step\n",
    "- we set split_rngs for the params to false. We don't want to create random parameters at each time step\n",
    "- now lets move over to the axes. In the aforementioned documentation, I'm constantly talking about timesteps. The axes is what allows me to talk about it in this way. Remember, the inputs are of shape (batch_size, timesteps, n_features). by specifying in_axis=1, we are saying, apply this function over the first dimension (i.e. the timesteps/sequence axis).\n",
    "- out_axis specifies the axis where the result will be added to (i.e. the dimension to place the results). As such, the output will have an extra dimension/axis at the position indicated by the `out_axis` (e.g. in the case of one sample with 10 output features, the shape would be (1, 10). with out_axis=1 the result would become (1, 1, 10))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/linen/transforms.py:138: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  new_args, new_kwargs = jax.tree_map(get_arg_scope, (args, kwargs))\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/linen/transforms.py:157: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  jax.tree_map(get_scopes_inner, attrs)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/lift.py:112: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  scopes, treedef = jax.tree_flatten(scope_tree)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/scope.py:322: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  group[col] = jax.tree_map(lambda x: x, xs[col])\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/lift.py:723: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  lengths = jax.tree_map(find_length, in_axes, args)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/lift.py:718: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  leaves = jax.tree_leaves(x)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/lift.py:724: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  lengths = set(jax.tree_leaves(lengths))\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/axes_scan.py:105: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  xs = jax.tree_map(transpose_to_front, in_axes, args)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/axes_scan.py:87: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  return jax.tree_map(trans, xs)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/axes_scan.py:123: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  carry_avals = jax.tree_map(\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/axes_scan.py:126: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  scan_avals = jax.tree_map(\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/axes_scan.py:131: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  in_avals, in_tree = jax.tree_flatten(input_avals)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/axes_scan.py:109: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  xs = jax.tree_map(lambda ax, arg, x: (arg if ax is broadcast else x),\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/lift.py:172: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  variables = jax.tree_map(lambda x: x, variables)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/linen/transforms.py:210: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  new_args, new_kwargs = jax.tree_map(\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/linen/transforms.py:235: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  new_attrs = jax.tree_map(set_scopes_inner, attrs)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/linen/transforms.py:247: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  jax.tree_leaves(tree)))\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/axes_scan.py:114: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  ys = jax.tree_map(lambda ax, y: (y if ax is broadcast else ()),\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/axes_scan.py:143: FutureWarning: jax.tree_unflatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_unflatten instead.\n",
      "  broadcast_in, constants_out = jax.tree_unflatten(out_tree(), out_flat)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/scope.py:740: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  abs_value_flat = jax.tree_leaves(abs_value)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/scope.py:741: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  value_flat = jax.tree_leaves(value)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/axes_scan.py:118: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  ys = jax.tree_map(lambda ax, y: (() if ax is broadcast else y),\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/axes_scan.py:146: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  ys = jax.tree_map(transpose_from_front, out_axes, ys)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/axes_scan.py:102: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  return jax.tree_map(trans, xs)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.9/lib/python3.9/site-packages/flax/core/axes_scan.py:147: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  ys = jax.tree_map(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16, 20, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example taken from flax documentation\n",
    "# --> https://flax.readthedocs.io/en/latest/api_reference/_autosummary/flax.linen.scan.html?highlight=flax%20scan\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "from jax import random\n",
    "\n",
    "class SimpleScan(nn.Module):\n",
    "  @nn.compact\n",
    "  def __call__(self, c, xs):\n",
    "    LSTM = nn.scan(nn.LSTMCell,\n",
    "                   variable_broadcast=\"params\",\n",
    "                   split_rngs={\"params\": False},\n",
    "                   in_axes=1,\n",
    "                   out_axes=1)\n",
    "    return LSTM()(c, xs)\n",
    "\n",
    "batch_size, seq_len, in_feat, out_feat = 16, 20, 3, 5\n",
    "key_1, key_2, key_3 = random.split(random.PRNGKey(0), 3)\n",
    "\n",
    "xs = random.uniform(key_1, (batch_size, seq_len, in_feat))\n",
    "init_carry = nn.LSTMCell.initialize_carry(key_2, (batch_size,), out_feat)\n",
    "\n",
    "model = SimpleScan()\n",
    "variables = model.init(key_3, init_carry, xs)\n",
    "out_carry, out_val = model.apply(variables, init_carry, xs)\n",
    "\n",
    "assert out_val.shape == (batch_size, seq_len, out_feat)\n",
    "out_val.shape \n",
    "# for each sample in the the batch (16 in total), at each time step (20 in total)\n",
    "# we have the knowledge 'encoded' in a 5 dimensional vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_carry[0].shape\n",
    "out_carry[1].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the encoder part of the model\n",
    "\n",
    "def select_carried_state(new_state, old_state):\n",
    "    return jnp.where(is_eos[:, np.newaxis], old_state, new_state)\n",
    "\n",
    "\n",
    "\n",
    "initial_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from typing import Any, Tuple\n",
    "\n",
    "from flax import linen as nn\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "Array = Any\n",
    "PRNGKey = Any\n",
    "\n",
    "class EncoderLSTM(nn.Module):\n",
    "  \"\"\"EncoderLSTM Module wrapped in a lifted scan transform.\"\"\"\n",
    "  eos_id: int\n",
    "\n",
    "  @functools.partial(\n",
    "      nn.scan,\n",
    "      variable_broadcast='params',\n",
    "      in_axes=1,\n",
    "      out_axes=1,\n",
    "      split_rngs={'params': False})\n",
    "  @nn.compact\n",
    "  def __call__(self, carry: Tuple[Array, Array],\n",
    "               x: Array) -> Tuple[Tuple[Array, Array], Array]:\n",
    "    \"\"\"Applies the module.\"\"\"\n",
    "    lstm_state, is_eos = carry\n",
    "    new_lstm_state, y = nn.LSTMCell()(lstm_state, x)\n",
    "    # Pass forward the previous state if EOS has already been reached.\n",
    "    def select_carried_state(new_state, old_state):\n",
    "      return jnp.where(is_eos[:, np.newaxis], old_state, new_state)\n",
    "    # LSTM state is a tuple (cell_state, hidden_state).\n",
    "    # we need to select what state to carry for both \n",
    "    # the cell_state as the hidden_state\n",
    "    carried_lstm_state = tuple(\n",
    "        select_carried_state(*s) for s in zip(new_lstm_state, lstm_state))\n",
    "    # Update `is_eos`.\n",
    "    is_eos = jnp.logical_or(is_eos, x[:, self.eos_id])\n",
    "    return (carried_lstm_state, is_eos), y\n",
    "\n",
    "  @staticmethod\n",
    "  def initialize_carry(batch_size: int, hidden_size: int) -> Tuple[Array, Array]:\n",
    "    # Use a dummy key since the default state init fn is just zeros.\n",
    "    return nn.LSTMCell.initialize_carry(\n",
    "        jax.random.PRNGKey(0), (batch_size,), hidden_size)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  \"\"\"LSTM encoder, returning state after finding the EOS token in the input.\"\"\"\n",
    "  hidden_size: int\n",
    "  eos_id: int\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, inputs: Array):\n",
    "    # inputs.shape = (batch_size, seq_length, vocab_size).\n",
    "    batch_size = inputs.shape[0]\n",
    "    lstm = EncoderLSTM(name='encoder_lstm', eos_id=self.eos_id)\n",
    "    init_lstm_state = lstm.initialize_carry(batch_size, self.hidden_size)\n",
    "    # We use the `is_eos` array to determine whether the encoder should carry\n",
    "    # over the last lstm state, or apply the LSTM cell on the previous state.\n",
    "    init_is_eos = jnp.zeros(batch_size, dtype=bool)\n",
    "    init_carry = (init_lstm_state, init_is_eos)\n",
    "    (final_state, _), _ = lstm(init_carry, inputs)\n",
    "    return final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],            dtype=float32),\n",
       " DeviceArray([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],            dtype=float32))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.LSTMCell().initialize_carry(jax.random.PRNGKey(0), (16, ), 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m xs[:, eos_idx]\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xs' is not defined"
     ]
    }
   ],
   "source": [
    "xs[:, eos_idx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch\u001b[39m.\u001b[39mkeys()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_batch() missing 1 required positional argument: 'step'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch \u001b[39m=\u001b[39m char_lookup_table\u001b[39m.\u001b[39mget_batch(\u001b[39m16\u001b[39m) \n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(batch[\u001b[39m'\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(batch[\u001b[39m'\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m'\u001b[39m][:, eos_idx]\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mTypeError\u001b[0m: get_batch() missing 1 required positional argument: 'step'"
     ]
    }
   ],
   "source": [
    "batch = char_lookup_table.get_batch(16) \n",
    "print(batch['query'].shape)\n",
    "print(batch['query'][:, eos_idx].shape)\n",
    "print(char_lookup_table.decode_onehot(batch['query'][:1]))\n",
    "print(batch['query'][0][:,eos_idx])\n",
    "char_lookup_table._char_indices\n",
    "\n",
    "# char_lookup_table.decode(batch['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([ True,  True,  True, False], dtype=bool)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in the network we initialize the is_eos with all zeros\n",
    "# then we compute the logical_or based on the input sequence where the id == eos_id\n",
    "# Finally, we take the xor, updating the is_eos matrix to contain ones, where the \n",
    "# is_eos matrix is one or the input_matrix is one \n",
    "jnp.logical_or(jnp.array([1,0,1,0]), jnp.array([1,1,0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_batch() missing 1 required positional argument: 'step'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m\n\u001b[1;32m      2\u001b[0m hidden_size \u001b[39m=\u001b[39m \u001b[39m512\u001b[39m\n\u001b[0;32m----> 3\u001b[0m batch \u001b[39m=\u001b[39m char_lookup_table\u001b[39m.\u001b[39mget_batch(batch_size)\n\u001b[1;32m      5\u001b[0m rng \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mPRNGKey(\u001b[39m0\u001b[39m)\n\u001b[1;32m      7\u001b[0m encoder_model \u001b[39m=\u001b[39m Encoder(hidden_size, char_lookup_table\u001b[39m.\u001b[39meos_id)\n",
      "\u001b[0;31mTypeError\u001b[0m: get_batch() missing 1 required positional argument: 'step'"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "hidden_size = 512\n",
    "batch = char_lookup_table.get_batch(batch_size)\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "\n",
    "encoder_model = Encoder(hidden_size, char_lookup_table.eos_id)\n",
    "example = jnp.ones((1, char_lookup_table.max_input_len, char_lookup_table.vocab_size), jnp.float32)\n",
    "variables = encoder_model.init(rng, example)\n",
    "model_params = variables['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch[\u001b[39m'\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "batch['query'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m encoding \u001b[39m=\u001b[39m encoder_model\u001b[39m.\u001b[39mapply({\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m: model_params\n\u001b[1;32m      3\u001b[0m }, batch[\u001b[39m'\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder_model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "encoding = encoder_model.apply({\n",
    "    \"params\": model_params\n",
    "}, batch['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m encoding[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape, encoding[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoding' is not defined"
     ]
    }
   ],
   "source": [
    "encoding[0].shape, encoding[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch\u001b[39m.\u001b[39mkeys()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DecoderLSTM(nn.Module):\n",
    "  \"\"\"DecoderLSTM Module wrapped in a lifted scan transform.\n",
    "  Attributes:\n",
    "    teacher_force: See docstring on Seq2seq module.\n",
    "    vocab_size: Size of the vocabulary.\n",
    "  \"\"\"\n",
    "  teacher_force: bool\n",
    "  vocab_size: int\n",
    "\n",
    "  @functools.partial(\n",
    "      nn.scan,\n",
    "      variable_broadcast='params',\n",
    "      in_axes=1,\n",
    "      out_axes=1,\n",
    "      split_rngs={'params': False, 'lstm': True})\n",
    "  @nn.compact\n",
    "  def __call__(self, carry: Tuple[Array, Array], x: Array) -> Array:\n",
    "    \"\"\"Applies the DecoderLSTM model.\"\"\"\n",
    "    lstm_state, last_prediction = carry\n",
    "    if not self.teacher_force:\n",
    "      x = last_prediction\n",
    "    lstm_state, y = nn.LSTMCell()(lstm_state, x)\n",
    "    logits = nn.Dense(features=self.vocab_size)(y)\n",
    "    # Sample the predicted token using a categorical distribution over the\n",
    "    # logits.\n",
    "    categorical_rng = self.make_rng('lstm')\n",
    "    predicted_token = jax.random.categorical(categorical_rng, logits)\n",
    "    # Convert to one-hot encoding.\n",
    "    prediction = jax.nn.one_hot(\n",
    "        predicted_token, self.vocab_size, dtype=jnp.float32)\n",
    "\n",
    "    return (lstm_state, prediction), (logits, prediction)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "  \"\"\"LSTM decoder.\n",
    "  Attributes:\n",
    "    init_state: [batch_size, hidden_size]\n",
    "      Initial state of the decoder (i.e., the final state of the encoder).\n",
    "    teacher_force: See docstring on Seq2seq module.\n",
    "    vocab_size: Size of the vocabulary.\n",
    "  \"\"\"\n",
    "  init_state: Tuple[Any]\n",
    "  teacher_force: bool\n",
    "  vocab_size: int\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, inputs: Array) -> Tuple[Array, Array]:\n",
    "    \"\"\"Applies the decoder model.\n",
    "    Args:\n",
    "      inputs: [batch_size, max_output_len-1, vocab_size]\n",
    "        Contains the inputs to the decoder at each time step (only used when not\n",
    "        using teacher forcing). Since each token at position i is fed as input\n",
    "        to the decoder at position i+1, the last token is not provided.\n",
    "    Returns:\n",
    "      Pair (logits, predictions), which are two arrays of respectively decoded\n",
    "      logits and predictions (in one hot-encoding format).\n",
    "    \"\"\"\n",
    "    lstm = DecoderLSTM(teacher_force=self.teacher_force,\n",
    "                       vocab_size=self.vocab_size)\n",
    "    init_carry = (self.init_state, inputs[:, 0])\n",
    "    _, (logits, predictions) = lstm(init_carry, inputs)\n",
    "    return logits, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m d \u001b[39m=\u001b[39m Decoder(init_state\u001b[39m=\u001b[39mencoding, teacher_force\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, vocab_size\u001b[39m=\u001b[39mchar_lookup_table\u001b[39m.\u001b[39mvocab_size)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoding' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "d = Decoder(init_state=encoding, teacher_force=False, vocab_size=char_lookup_table.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_decoder_input = char_lookup_table.one_hot(char_lookup_table.encode('=')[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m init_decoder_inputs \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mtile(init_decoder_input,\n\u001b[0;32m----> 2\u001b[0m                                 (batch[\u001b[39m'\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], char_lookup_table\u001b[39m.\u001b[39mmax_output_len, \u001b[39m1\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "init_decoder_inputs = jnp.tile(init_decoder_input,\n",
    "                                (batch['query'].shape[0], char_lookup_table.max_output_len, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'init_decoder_inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m init_decoder_input\u001b[39m.\u001b[39mshape, init_decoder_inputs\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'init_decoder_inputs' is not defined"
     ]
    }
   ],
   "source": [
    "init_decoder_input.shape, init_decoder_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m key_1, key_2 \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39msplit(jax\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mPRNGKey(\u001b[39m0\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m decoder_params \u001b[39m=\u001b[39m d\u001b[39m.\u001b[39minit({\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m:key_1, \u001b[39m\"\u001b[39m\u001b[39mlstm\u001b[39m\u001b[39m\"\u001b[39m: key_2}, init_decoder_inputs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "key_1, key_2 = jax.random.split(jax.random.PRNGKey(0))\n",
    "decoder_params = d.init({\"params\":key_1, \"lstm\": key_2}, init_decoder_inputs)\n",
    "# d.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39m# we need a random key as our decoder samples \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# using a categorical distibution based on the logits\u001b[39;00m\n\u001b[1;32m      5\u001b[0m lstm_key \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mfold_in(lstm_rng, step) \n\u001b[0;32m----> 7\u001b[0m logits, predictions \u001b[39m=\u001b[39m d\u001b[39m.\u001b[39mapply(decoder_params, init_decoder_inputs, rngs\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mlstm\u001b[39m\u001b[39m'\u001b[39m: lstm_key})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "lstm_rng = jax.random.PRNGKey(0)\n",
    "step = 200\n",
    "# we need a random key as our decoder samples \n",
    "# using a categorical distibution based on the logits\n",
    "lstm_key = jax.random.fold_in(lstm_rng, step) \n",
    "\n",
    "logits, predictions = d.apply(decoder_params, init_decoder_inputs, rngs={'lstm': lstm_key})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m logits\u001b[39m.\u001b[39mshape, predictions\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logits' is not defined"
     ]
    }
   ],
   "source": [
    "logits.shape, predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# model isn't trained, but here are the results (query, target, prediction)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(char_lookup_table\u001b[39m.\u001b[39mdecode_onehot(batch[\u001b[39m'\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(char_lookup_table\u001b[39m.\u001b[39mdecode_onehot(batch[\u001b[39m'\u001b[39m\u001b[39manswer\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(char_lookup_table\u001b[39m.\u001b[39mdecode_onehot(predictions))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "# model isn't trained, but here are the results (query, target, prediction)\n",
    "print(char_lookup_table.decode_onehot(batch['query']))\n",
    "print(char_lookup_table.decode_onehot(batch['answer']))\n",
    "print(char_lookup_table.decode_onehot(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(nn.Module):\n",
    "\n",
    "    teacher_force: bool\n",
    "    hidden_size: int\n",
    "    vocab_size: int\n",
    "    eos_id: int = 1\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, encoder_inputs, decoder_inputs):\n",
    "        initial_decoder_state = Encoder(\n",
    "            hidden_size=self.hidden_size,\n",
    "            eos_id=self.eos_id\n",
    "        )(encoder_inputs)\n",
    "\n",
    "        logits, predictions = Decoder(\n",
    "            init_state=initial_decoder_state,\n",
    "            teacher_force=self.teacher_force,\n",
    "            vocab_size=self.vocab_size\n",
    "        )(decoder_inputs[:, :-1])\n",
    "        return logits, predictions\n",
    "\n",
    "    # @nn.compact\n",
    "    # def __call__(self, encoder_inputs, decoder_inputs):\n",
    "    #     initial_decoder_state = Encoder(\n",
    "    #         hidden_size=self.hidden_size,\n",
    "    #         eos_id=self.eos_id\n",
    "    #     )(encoder_inputs)\n",
    "\n",
    "    #     logits, predictions = Decoder(\n",
    "    #         init_state=initial_decoder_state,\n",
    "    #         teacher_force=self.teacher_force,\n",
    "    #         vocab_size=self.vocab_size\n",
    "    #     )(decoder_inputs[:, :-1])\n",
    "    #     return logits, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_force = False\n",
    "hidden_size = 512\n",
    "eos_id = char_lookup_table.eos_id\n",
    "vocab_size = char_lookup_table.vocab_size\n",
    "model = Seq2seq(\n",
    "    teacher_force=teacher_force,\n",
    "    hidden_size=hidden_size,\n",
    "    vocab_size=vocab_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "params_key, lstm_key = jax.random.split(rng)\n",
    "max_input_sequence_len = char_lookup_table.max_input_len\n",
    "max_output_sequence_len = char_lookup_table.max_output_len\n",
    "variables = model.init(\n",
    "    {\n",
    "        \"params\": params_key,\n",
    "        \"lstm\": lstm_key\n",
    "    },\n",
    "    jnp.ones((batch_size, max_input_sequence_len, vocab_size), dtype=jnp.float32),\n",
    "    jnp.ones((batch_size, max_output_sequence_len, vocab_size), dtype=jnp.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozen_dict_keys(['params'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([[[ 0.08307394, -0.06417654,  0.11232382, ...,  0.04796918,\n",
       "                 0.08337983, -0.04808454],\n",
       "               [-0.04887169,  0.02889351,  0.08376509, ..., -0.0573354 ,\n",
       "                 0.02569693, -0.01780605],\n",
       "               [ 0.07617846, -0.06507105,  0.15715244, ...,  0.07221642,\n",
       "                 0.12518902, -0.0459436 ],\n",
       "               ...,\n",
       "               [ 0.08691359, -0.09904549,  0.05844625, ...,  0.03085802,\n",
       "                -0.13066357, -0.01850299],\n",
       "               [ 0.17952195,  0.04801203,  0.10827539, ..., -0.02468754,\n",
       "                 0.0370799 , -0.06572822],\n",
       "               [ 0.03389015,  0.00849534,  0.0068223 , ...,  0.00689863,\n",
       "                 0.0393358 , -0.11326101]],\n",
       " \n",
       "              [[ 0.09038381, -0.08036304,  0.10141592, ...,  0.02821084,\n",
       "                 0.10218308, -0.02035185],\n",
       "               [ 0.13380422,  0.05083488,  0.04915942, ..., -0.10524669,\n",
       "                 0.10610627,  0.05437368],\n",
       "               [ 0.1284994 ,  0.04025817,  0.10398245, ...,  0.0349204 ,\n",
       "                 0.05961333,  0.07432193],\n",
       "               ...,\n",
       "               [ 0.09459567,  0.04841722,  0.01790352, ...,  0.04476517,\n",
       "                 0.10109463, -0.04270589],\n",
       "               [ 0.00675489,  0.00334709, -0.00370746, ...,  0.04632333,\n",
       "                 0.06944169, -0.02370582],\n",
       "               [-0.09398853,  0.09772126,  0.07149192, ...,  0.00074859,\n",
       "                 0.0656438 ,  0.06745849]],\n",
       " \n",
       "              [[ 0.07680565, -0.09538081,  0.09987976, ...,  0.04093312,\n",
       "                 0.1050894 , -0.04485584],\n",
       "               [ 0.13545579,  0.03345525,  0.07192907, ..., -0.10171738,\n",
       "                 0.10734063,  0.05127335],\n",
       "               [ 0.16030747,  0.06720173,  0.04631138, ..., -0.03007051,\n",
       "                 0.11283469, -0.01511302],\n",
       "               ...,\n",
       "               [ 0.02307737,  0.02021651,  0.00511848, ...,  0.01125195,\n",
       "                 0.08222268,  0.09970434],\n",
       "               [ 0.11171512, -0.06451995,  0.05473147, ...,  0.06351745,\n",
       "                -0.03447008,  0.1520299 ],\n",
       "               [ 0.1278329 ,  0.01526029, -0.00529008, ...,  0.03921251,\n",
       "                 0.08008413,  0.02792082]],\n",
       " \n",
       "              ...,\n",
       " \n",
       "              [[ 0.08257927, -0.10460095,  0.12600534, ...,  0.00957109,\n",
       "                 0.07924028, -0.05781667],\n",
       "               [ 0.18267936,  0.06472795,  0.14642555, ..., -0.01868905,\n",
       "                 0.11242551, -0.10092239],\n",
       "               [ 0.1701081 ,  0.07056701,  0.1303871 , ...,  0.08835557,\n",
       "                 0.04416277, -0.01921787],\n",
       "               ...,\n",
       "               [ 0.05628004, -0.03972441, -0.02750922, ...,  0.07301001,\n",
       "                 0.05038077,  0.0243116 ],\n",
       "               [ 0.04917509, -0.06423827, -0.0043033 , ...,  0.08566882,\n",
       "                -0.03706946, -0.05800579],\n",
       "               [ 0.12986106, -0.09331776, -0.10167679, ...,  0.13042092,\n",
       "                -0.12303941,  0.01904944]],\n",
       " \n",
       "              [[ 0.12249661, -0.10386096,  0.14680502, ...,  0.03140073,\n",
       "                 0.1209379 , -0.02279596],\n",
       "               [ 0.15850413, -0.09523652,  0.03450573, ...,  0.08974424,\n",
       "                 0.06074852, -0.11927556],\n",
       "               [ 0.02610465, -0.03669495, -0.02579285, ...,  0.05154156,\n",
       "                 0.04512806, -0.10227554],\n",
       "               ...,\n",
       "               [-0.09281497, -0.03002914, -0.06460758, ...,  0.0139387 ,\n",
       "                 0.02901088, -0.01999728],\n",
       "               [-0.15697698,  0.07957149,  0.02117227, ..., -0.02148688,\n",
       "                 0.05300506,  0.04192068],\n",
       "               [-0.05830166, -0.0179526 ,  0.04880999, ...,  0.09537116,\n",
       "                -0.0014839 ,  0.09850807]],\n",
       " \n",
       "              [[ 0.04347707, -0.11192491,  0.11110252, ...,  0.05734334,\n",
       "                 0.10103773, -0.08062863],\n",
       "               [ 0.16898783,  0.03910859,  0.15406752, ..., -0.0004376 ,\n",
       "                 0.12748009, -0.09469486],\n",
       "               [ 0.18890624,  0.00332251,  0.03636713, ...,  0.08977721,\n",
       "                 0.06128837, -0.1817157 ],\n",
       "               ...,\n",
       "               [-0.01285942,  0.06446112,  0.02878608, ..., -0.06165402,\n",
       "                 0.02645415, -0.04286392],\n",
       "               [ 0.18508667,  0.1365033 ,  0.10097197, ..., -0.040463  ,\n",
       "                 0.13365299, -0.06287558],\n",
       "               [ 0.16189827, -0.010416  ,  0.13511407, ...,  0.09229138,\n",
       "                 0.15598388, -0.09069349]]], dtype=float32),\n",
       " DeviceArray([[[0., 1., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 1.],\n",
       "               [1., 0., 0., ..., 0., 0., 0.],\n",
       "               ...,\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 1., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "              [[0., 0., 0., ..., 1., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 1., ..., 0., 0., 0.],\n",
       "               ...,\n",
       "               [0., 0., 1., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 1., ..., 0., 0., 0.]],\n",
       " \n",
       "              [[0., 0., 0., ..., 1., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               ...,\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "              ...,\n",
       " \n",
       "              [[0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               ...,\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "              [[0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 1., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 1., 0.],\n",
       "               ...,\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "              [[0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               ...,\n",
       "               [0., 0., 0., ..., 0., 0., 0.],\n",
       "               [0., 0., 0., ..., 0., 0., 1.],\n",
       "               [0., 0., 0., ..., 1., 0., 0.]]], dtype=float32))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(variables, batch['query'], batch['answer'], rngs={\n",
    "    \"lstm\": lstm_key\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 8, 14)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# model.apply(variables, batch['query'], batch['answer'], rngs={\n",
    "#     \"lstm\": lstm_key\n",
    "# })\n",
    "# during inference you provide the start_of_sentence token\n",
    "# which in our case is the '=' character \n",
    "batch['answer'].shape # <-- input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 6, 14)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_decoder_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],            dtype=float32),\n",
       " {'+': 2,\n",
       "  '0': 3,\n",
       "  '1': 4,\n",
       "  '2': 5,\n",
       "  '3': 6,\n",
       "  '4': 7,\n",
       "  '5': 8,\n",
       "  '6': 9,\n",
       "  '7': 10,\n",
       "  '8': 11,\n",
       "  '9': 12,\n",
       "  '=': 13})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_decoder_inputs[0], char_lookup_table._char_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/linen/transforms.py:138: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  new_args, new_kwargs = jax.tree_map(get_arg_scope, (args, kwargs))\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/linen/transforms.py:157: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  jax.tree_map(get_scopes_inner, attrs)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/lift.py:112: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  scopes, treedef = jax.tree_flatten(scope_tree)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/scope.py:322: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  group[col] = jax.tree_map(lambda x: x, xs[col])\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/lift.py:723: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  lengths = jax.tree_map(find_length, in_axes, args)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/lift.py:718: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  leaves = jax.tree_leaves(x)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/lift.py:724: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  lengths = set(jax.tree_leaves(lengths))\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/axes_scan.py:105: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  xs = jax.tree_map(transpose_to_front, in_axes, args)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/axes_scan.py:87: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  return jax.tree_map(trans, xs)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/axes_scan.py:123: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  carry_avals = jax.tree_map(\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/axes_scan.py:126: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  scan_avals = jax.tree_map(\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/axes_scan.py:131: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  in_avals, in_tree = jax.tree_flatten(input_avals)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/axes_scan.py:109: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  xs = jax.tree_map(lambda ax, arg, x: (arg if ax is broadcast else x),\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/lift.py:172: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  variables = jax.tree_map(lambda x: x, variables)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/linen/transforms.py:210: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  new_args, new_kwargs = jax.tree_map(\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/linen/transforms.py:235: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  new_attrs = jax.tree_map(set_scopes_inner, attrs)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/linen/transforms.py:247: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  jax.tree_leaves(tree)))\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/axes_scan.py:114: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  ys = jax.tree_map(lambda ax, y: (y if ax is broadcast else ()),\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/axes_scan.py:143: FutureWarning: jax.tree_unflatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_unflatten instead.\n",
      "  broadcast_in, constants_out = jax.tree_unflatten(out_tree(), out_flat)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/scope.py:740: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  abs_value_flat = jax.tree_leaves(abs_value)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/scope.py:741: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  value_flat = jax.tree_leaves(value)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/axes_scan.py:118: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  ys = jax.tree_map(lambda ax, y: (() if ax is broadcast else y),\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/axes_scan.py:146: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  ys = jax.tree_map(transpose_from_front, out_axes, ys)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/axes_scan.py:102: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  return jax.tree_map(trans, xs)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/axes_scan.py:147: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  ys = jax.tree_map(\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/lift.py:42: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  return jax.tree_map(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import functools\n",
    "from typing import Callable, Dict, List\n",
    "\n",
    "import absl\n",
    "\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "from flax.metrics import tensorboard\n",
    "import flax.optim\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from jax.experimental import jax2tf\n",
    "from mlteacher.mlops.transform import CharacterTable\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# The transformed feature names\n",
    "\n",
    "# Type abbreviations: (B is the batch size)\n",
    "_Array = np.ndarray\n",
    "_InputBatch = Dict[str,\n",
    "                   _Array]  # keys are _FEATURE_KEYS_XF and values f32[B, 1]\n",
    "_LogitBatch = _Array  # of shape f32[B, 3]\n",
    "_LabelBatch = _Array  # of shape int64[B, 1]\n",
    "_Params = Dict[str, _Array]\n",
    "\n",
    "\n",
    "class _SavedModelWrapper(tf.train.Checkpoint):\n",
    "  \"\"\"Wraps a function and its parameters for saving to a SavedModel.\n",
    "  Implements the interface described at\n",
    "  https://www.tensorflow.org/hub/reusable_saved_models.\n",
    "  This class contains all the code needed to convert a Flax model to a\n",
    "  TensorFlow saved model.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               tf_graph: Callable[[_InputBatch], _Array],\n",
    "               param_vars: Dict[str, tf.Variable]):\n",
    "    \"\"\"Builds the tf.Module.\n",
    "    Args:\n",
    "      tf_graph: a tf.function taking one argument (the inputs), which can be be\n",
    "        tuples/lists/dictionaries of np.ndarray or tensors. The function may\n",
    "        have references to the tf.Variables in `param_vars`.\n",
    "      param_vars: the parameters, as tuples/lists/dictionaries of tf.Variable,\n",
    "        to be saved as the variables of the SavedModel.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    # Implement the interface from\n",
    "    # https://www.tensorflow.org/hub/reusable_saved_models\n",
    "    self.variables = tf.nest.flatten(param_vars)\n",
    "    self.trainable_variables = [v for v in self.variables if v.trainable]\n",
    "    self._tf_graph = tf_graph\n",
    "\n",
    "  @tf.function\n",
    "  def __call__(self, inputs):\n",
    "    return self._tf_graph(inputs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from mlteacher.mlops import train, models\n",
    "\n",
    "def save_model():\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    ctable = CharacterTable(\"0123456789=+\")\n",
    "    model = models.Seq2seq(teacher_force=False, hidden_size=512, vocab_size=ctable.vocab_size)\n",
    "    params = train.get_initial_params(model, rng, ctable)\n",
    "\n",
    "    batch_size = 1\n",
    "    step = 1\n",
    "    batch = ctable.get_batch(batch_size=batch_size, step=step)\n",
    "    model.apply({\"params\": params}, batch['query'], batch['answer'], rngs={\"lstm\":jax.random.PRNGKey(1)})\n",
    "    predict_fn = lambda params, input: model.apply({\"params\": params}, *input, rngs={\"lstm\":jax.random.PRNGKey(1)})\n",
    "    tf_fn = jax2tf.convert(predict_fn, with_gradient=False, enable_xla=True)\n",
    "\n",
    "    return tf_fn, params\n",
    "tf_fn, trained_params = save_model()                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 19:56:40.363922: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-10-20 19:56:40.363962: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'flax.core.frozen_dict.FrozenDict'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_vars = tf.nest.map_structure(\n",
    "    # Due to a bug in SavedModel it is not possible to use tf.GradientTape\n",
    "    # on a function converted with jax2tf and loaded from SavedModel.\n",
    "    # Thus, we mark the variables as non-trainable to ensure that users of\n",
    "    # the SavedModel will not try to fine tune them.\n",
    "    lambda param: tf.Variable(param, trainable=False),\n",
    "    trained_params)\n",
    "tf_graph = tf.function(\n",
    "    lambda inputs, decoder_inputs: tf_fn(param_vars, (inputs, decoder_inputs)),\n",
    "    autograph=False,\n",
    "    experimental_compile=True)\n",
    "\n",
    "signatures = {}\n",
    "# This signature is needed for TensorFlow Serving use.\n",
    "batch_size = 1\n",
    "ctable = CharacterTable(\"0123456789+=\")\n",
    "ctable.get_batch(1, 1)['query'].shape\n",
    "input_signatures = [\n",
    "            tf.TensorSpec((batch_size,) + (ctable.max_input_len, ctable.vocab_size), tf.float32),\n",
    "            tf.TensorSpec((batch_size,) + (ctable.max_output_len, ctable.vocab_size), tf.float32)\n",
    "          ]\n",
    "signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY] = tf_graph.get_concrete_function(input_signatures[0], input_signatures[1])\n",
    "\n",
    "tf_model = _SavedModelWrapper(tf_graph, param_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'serving_default': <ConcreteFunction <lambda>(inputs, decoder_inputs) at 0x7F11267867F0>}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, signatures, serving_dir):\n",
    "    latest_model = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    serving_dir = os.path.join(serving_dir, latest_model)\n",
    "    tf.saved_model.save(tf_model, serving_dir, signatures=signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/linen/transforms.py:138: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  new_args, new_kwargs = jax.tree_map(get_arg_scope, (args, kwargs))\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/linen/transforms.py:157: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  jax.tree_map(get_scopes_inner, attrs)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/lift.py:112: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  scopes, treedef = jax.tree_flatten(scope_tree)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/scope.py:322: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  group[col] = jax.tree_map(lambda x: x, xs[col])\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/lift.py:723: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  lengths = jax.tree_map(find_length, in_axes, args)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/lift.py:718: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  leaves = jax.tree_leaves(x)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/lift.py:724: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  lengths = set(jax.tree_leaves(lengths))\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/axes_scan.py:105: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  xs = jax.tree_map(transpose_to_front, in_axes, args)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/axes_scan.py:87: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  return jax.tree_map(trans, xs)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/axes_scan.py:123: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  carry_avals = jax.tree_map(\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/axes_scan.py:126: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  scan_avals = jax.tree_map(\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/axes_scan.py:131: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  in_avals, in_tree = jax.tree_flatten(input_avals)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/axes_scan.py:109: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  xs = jax.tree_map(lambda ax, arg, x: (arg if ax is broadcast else x),\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/lift.py:172: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  variables = jax.tree_map(lambda x: x, variables)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/linen/transforms.py:210: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  new_args, new_kwargs = jax.tree_map(\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/linen/transforms.py:235: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  new_attrs = jax.tree_map(set_scopes_inner, attrs)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/scope.py:740: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  abs_value_flat = jax.tree_leaves(abs_value)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/scope.py:741: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  value_flat = jax.tree_leaves(value)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/linen/transforms.py:247: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  jax.tree_leaves(tree)))\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/axes_scan.py:114: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  ys = jax.tree_map(lambda ax, y: (y if ax is broadcast else ()),\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/axes_scan.py:143: FutureWarning: jax.tree_unflatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_unflatten instead.\n",
      "  broadcast_in, constants_out = jax.tree_unflatten(out_tree(), out_flat)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/axes_scan.py:118: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  ys = jax.tree_map(lambda ax, y: (() if ax is broadcast else y),\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/axes_scan.py:146: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  ys = jax.tree_map(transpose_from_front, out_axes, ys)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/axes_scan.py:102: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  return jax.tree_map(trans, xs)\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/axes_scan.py:147: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  ys = jax.tree_map(\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/mlteacher-qwQzX-qT-py3.8/lib/python3.8/site-packages/flax/core/lift.py:42: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  return jax.tree_map(\n",
      "WARNING:absl:Found untraced functions such as __call__ while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "save_model(tf_model, signatures,  \"../../../mlteacher/models/brain/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "loaded_model = tf.saved_model.load(\"/workspaces/MLOpsWithJax/src/mlteacher/models/brain/20221020124847\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_default = loaded_model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlteacher import config\n",
    "\n",
    "ctable = transform.CharacterTable(\n",
    "    '0123456789+= ', config.TrainConfig.max_len_query_digit)\n",
    "# ctable = CharacterTable(\"0123456789=+\")\n",
    "b = ctable.get_batch(1, 2)\n",
    "q, a = b['query'], b['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       "  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       "  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "decoder_input_a = jnp.zeros_like(a)\n",
    "decoder_input_a[:, :6, :].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_0': <tf.Tensor: shape=(1, 5, 14), dtype=float32, numpy=\n",
       " array([[[ 0.04452905, -0.02319412,  0.02610207,  0.03594843,\n",
       "          -0.01173355, -0.08520072, -0.00829763,  0.10091518,\n",
       "          -0.06154622,  0.01647665,  0.02164995, -0.01271162,\n",
       "           0.00583454,  0.06530214],\n",
       "         [ 0.00173595,  0.05773558,  0.14703731,  0.01773059,\n",
       "           0.04543342, -0.1435977 , -0.09084816, -0.02898849,\n",
       "           0.02558784,  0.05243998,  0.13085285, -0.1132612 ,\n",
       "          -0.03834904, -0.00568175],\n",
       "         [-0.04256568,  0.0139187 ,  0.06434848,  0.08148213,\n",
       "           0.01206123, -0.1935127 ,  0.00626391,  0.03290744,\n",
       "           0.00289503,  0.04359363,  0.13530481, -0.03515957,\n",
       "          -0.01334131, -0.07012346],\n",
       "         [-0.11977271,  0.08828357,  0.10907937, -0.06655134,\n",
       "           0.00992293, -0.08000052,  0.0345731 ,  0.0150109 ,\n",
       "          -0.06789728, -0.09775098,  0.07344852, -0.03305475,\n",
       "           0.01745135,  0.01585141],\n",
       "         [-0.030447  ,  0.09042929,  0.02350833, -0.09037516,\n",
       "          -0.10219177, -0.16376711,  0.09159495,  0.05602517,\n",
       "          -0.07791158, -0.03043813, -0.06547426,  0.00067108,\n",
       "           0.08893485, -0.05602361]]], dtype=float32)>,\n",
       " 'output_1': <tf.Tensor: shape=(1, 5, 14), dtype=float32, numpy=\n",
       " array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]],\n",
       "       dtype=float32)>}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_default(inputs=q, decoder_inputs=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME=brain\n",
    "docker run -t --rm -p 8501:8501 --mount type=bind,source=$PWD/models/$MODEL_NAME,target=/models/$MODEL_NAME/ -e MODEL_NAME=$MODEL_NAME -e --xla_cpu_compilation_enabled=true docker.io/tensorflow/serving:latest --xla_cpu_compilation_enabled=true &\n",
    "curl -X POST -d @sample.json http://127.0.0.1:8501/v1/models/$MODEL_NAME:predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class RegistryOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "class AzureMLConfig:\n",
    "    subscription_id = os.environ.get(\"SUBSCRIPTION_ID\", \"0abb6ec5-9030-4b3f-af04-09183c688576\")\n",
    "    resource_group_name = os.environ.get(\"RESOURCE_GROUP\", \"csu-nl-intelligence\")\n",
    "    workspace_name = os.environ.get(\"AZUREML_WORKSPACE_NAME\", \"mlpatterns\")\n",
    "\n",
    "\n",
    "\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=AzureMLConfig.subscription_id,\n",
    "    resource_group_name=AzureMLConfig.resource_group_name,\n",
    "    workspace_name=AzureMLConfig.workspace_name,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "model = Model(\n",
    "    path=\"/workspaces/MLOpsWithJax/src/mlteacher/models/brain\",\n",
    "    type=\"custom_model\",\n",
    "    name=\"brain\",\n",
    "    version=\"1\",\n",
    "    description=\"A JAX sequence2sequence model served with Azure ML and Tensorflow Serving\"\n",
    ")\n",
    "\n",
    "registered_model = ml_client.models.create_or_update(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(\"/workspaces/MLOpsWithJax/src/mlteacher/models/brain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a unique endpoint name with current datetime to avoid conflicts\n",
    "import datetime\n",
    "# import required libraries\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import (\n",
    "   ManagedOnlineEndpoint,\n",
    "   ManagedOnlineDeployment,\n",
    "   Model,\n",
    "   Environment,\n",
    "   CodeConfiguration,\n",
    ")\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# online_endpoint_name = \"endpoint-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
    "online_endpoint_name = \"jax-online-endpoint\"\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"this is a sample online endpoint\",\n",
    "    auth_mode=\"key\",\n",
    "    tags={\"foo\": \"bar\"},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.14 ('mlteacher-qwQzX-qT-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08626ac9f967e5febaed3981e0a443fb739b660a4eba71ae8ed7bd4be6194b2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
